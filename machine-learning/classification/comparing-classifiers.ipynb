{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LWd1UlMnhT2s"
   },
   "source": [
    "![](header.jpg)\n",
    "\n",
    "# Classifiers\n",
    "\n",
    "Kevin J. Walchko, Phd\n",
    "\n",
    "23 Dec 2020\n",
    "\n",
    "---\n",
    "\n",
    "## Linear Classifiers\n",
    "\n",
    "Linear classifier maps raw data:\n",
    "\n",
    "$$\n",
    "f(x_i, W, b) = Wx_i + b\n",
    "$$\n",
    "\n",
    "- $x_i$: data (kx 1), ex: image with pixels flattened\n",
    "- $W$: weight matrix (k x D), each row is a classifier\n",
    "- $b$: bias vector (k x 1)\n",
    "\n",
    "### Linear Regression\n",
    "\n",
    "$$\n",
    "y = b_0 + b_1 x_1 + ... + b_n x_n\n",
    "$$\n",
    "\n",
    "- n: n=1 is a simple linear system, n > 1 is a multiple linear system\n",
    "    - Don't need to do feature scaling for n > 1, coefficients (b's) will handle data of different sizes \n",
    "- $b_0$: bias, y-intercept\n",
    "- $b_1$: scale/slope\n",
    "\n",
    "1. `fit()`: trains the regressor\n",
    "1. `predict()`: use test data, should align with training data\n",
    "\n",
    "Assumptions of linear regression\n",
    "\n",
    "1. Linearity\n",
    "1. Homoscedasticity\n",
    "1. Multivariance normality\n",
    "1. Independence of errors\n",
    "1. Lack of multi-collinearity\n",
    "    - To handle catagorical variables, can create a dummy variable ($D_i$)\n",
    "        - Example: $y = b_0 + b_1 x_1 + b_2 D_1$\n",
    "    - If one variable can predict another variable, then during training, the algorithm cannot determine the effects of one from another, bad: $D_2 = 1 - D_1$\n",
    "    - Always omit one dummy variable in multilinear systems, $b_0$ can represent a $D_i$ when multiple dummy variables are used\n",
    "\n",
    "## Examples\n",
    "\n",
    "This notebook takes a set of data and applies several linear and non-linear classifiers. The data set is a simple one, with two independent variables (age and salary) and one dependent variable (did a customer buy a product).\n",
    "\n",
    "Below are plots of the resulting models which are trying to predict (or classify) if a customer, based on age and income, will buy a product. The outcome is not a continous value, but rather a boolean (true/false or yes/no) in this case. \n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Training Dataset</th>\n",
    "    <th>Test Dataset</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img src=\"logrithmic-pics/train.png\"></td>\n",
    "    <td><img src=\"logrithmic-pics/test.png\"></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img src=\"knn-pics/training.png\"></td>\n",
    "    <td><img src=\"knn-pics/test.png\"></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img src=\"svm-pics/train.png\"></td>\n",
    "    <td><img src=\"svm-pics/test.png\"></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img src=\"ksvm-pics/train.png\"></td>\n",
    "    <td><img src=\"ksvm-pics/test.png\"></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img src=\"decision-tree-pics/train.png\"></td>\n",
    "    <td><img src=\"decision-tree-pics/test.png\"></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img src=\"random-forest-pics/train.png\"></td>\n",
    "    <td><img src=\"random-forest-pics/test.png\"></td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "A summary of the results for each classifier is below. Since the data points for\n",
    "\"buy\" or \"don't buy\" are very intertwined, it is difficult to draw a straight line\n",
    "through the points separating them. Therefore it is expected that linear models\n",
    "will not perform as well as nonlinear models.\n",
    "\n",
    "| Name                | Type      |Accuracy |\n",
    "|---------------------|-----------|-----|\n",
    "| Logistic Regression | linear    | 89% |\n",
    "| K-Nearest Neighbor  | nonlinear | 93% |\n",
    "| SVM                 | linear    | 90% |\n",
    "| Kernel SVM          | nonlinear | 93% |\n",
    "| Decision Tree       | nonlinear | 91% |\n",
    "| Random Forest       | nonlinear | 91% |\n",
    "\n",
    "The last two nonlinear models do not perform as well as expected, this is probably\n",
    "due to over fitting of the training set. Notice in the pictures above, how there\n",
    "are sever \"little islands\" of different colors trying to capture all of the training\n",
    "data. However, when the test data is applied, all of those islands do not perform\n",
    "well. Here, the KNN and Kernal SVM which are able to weave a \"smooth\" line through\n",
    "the data out performs the others.\n",
    "\n",
    "## References\n",
    "\n",
    "- Stanford: [CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/)\n",
    "- Machine Learning class on udemy.com\n",
    "- wikipedia: [k-nearest neighbors algorithm](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)\n",
    "- [Machine Learning Basics with the K-Nearest Neighbors Algorithm](https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YvGPUQaHhXfL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from colorama import Fore\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print(\"-------------------\")\n",
    "    print(f\"{Fore.GREEN}True Positives (TP): {cm[0,0]}\")\n",
    "    print(f\"True Negatives (TN): {cm[1,1]}\")\n",
    "    print(f\"{Fore.RED}False Positives (FP): {cm[0,1]}\")\n",
    "    print(f\"False Negatives (FN): {cm[1,0]}{Fore.RESET}\")\n",
    "    print(\"-------------------\")\n",
    "    print(f\"Accuracy: {100*accuracy_score(y_test, y_pred)}%\")\n",
    "\n",
    "    print(f\"Prediction: {lr.predict(sc.transform([[30,87000]]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K1VMqkGvhc3-"
   },
   "source": [
    "# Data Conditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M52QDmyzhh9s"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  EstimatedSalary  Purchased\n",
       "0   19            19000          0\n",
       "1   35            20000          0\n",
       "2   26            43000          0\n",
       "3   27            57000          0\n",
       "4   19            76000          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset describing the age and salary of people who\n",
    "# purchased something from an advertisement. The Purchased\n",
    "# data is just binary signifying if a purchase was made.\n",
    "dataset = pd.read_csv('../datasets/Social_Network_Ads.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37.655000</td>\n",
       "      <td>69742.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.482877</td>\n",
       "      <td>34096.960282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>29.750000</td>\n",
       "      <td>43000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>88000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age  EstimatedSalary\n",
       "count  400.000000       400.000000\n",
       "mean    37.655000     69742.500000\n",
       "std     10.482877     34096.960282\n",
       "min     18.000000     15000.000000\n",
       "25%     29.750000     43000.000000\n",
       "50%     37.000000     70000.000000\n",
       "75%     46.000000     88000.000000\n",
       "max     60.000000    150000.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we are removing the binary \"Purchased\" value\n",
    "# because the results are meaningless for it\n",
    "dataset[[\"Age\",\"EstimatedSalary\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AVzJWAXIhxoC"
   },
   "outputs": [],
   "source": [
    "# so looking at the dataset, our independent variables (X) \n",
    "# are Age and Salary, while our dependent variable (Y) is\n",
    "# did they purchase a product or not.\n",
    "X = dataset.iloc[:, :-1].values # grab everything upto the last column\n",
    "y = dataset.iloc[:, -1].values  # grab the last column\n",
    "\n",
    "x_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "    test_size = 0.25, # reserve 25% of data for testing\n",
    "    random_state = 0) # random_state initializes the seed to 0 everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2393,
     "status": "ok",
     "timestamp": 1588492962259,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "P3nS3-6r1i2B",
    "outputId": "2972f900-ae1f-493b-9097-11ab9314d030"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean values are: [   38.13 69583.33]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mv = np.mean(x_train,axis=0)\n",
    "print(f\"Mean values are: {mv}\")\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(x_train[:,0])\n",
    "plt.grid(True)\n",
    "plt.title(\"Age\");\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(x_train[:,1])\n",
    "plt.grid(True)\n",
    "plt.title(\"Salary\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2386,
     "status": "ok",
     "timestamp": 1588492962260,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "8dpDLojm1mVG",
    "outputId": "f2afb6eb-2911-439a-d6b6-9e025bbedc75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1\n",
      " 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 1 0 1\n",
      " 1 1 0 0 1 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1 1 1 0 1 1 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0\n",
      " 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1\n",
      " 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# note again, it is just binary output of:\n",
    "#    0 - didn't purchase\n",
    "#    1 - did purchase\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kW3c7UYih0hT"
   },
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Below, we are going to scale the `x_train` and `x_test` datasets because the numbers within them are in completely different ranges. \n",
    "\n",
    "You might ask, \"why don't we scale the y output\" ... well look at it above. It is already scaled from \\[0,1\\] ... no need to do anything. If this data HAD other values (like \\[-30,215\\] for example) then we would have scaled it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9fQlDPKCh8sc"
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(x_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2367,
     "status": "ok",
     "timestamp": 1588492962261,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "syrnD1Op2BSR",
    "outputId": "721c0899-23c8-42ff-dc5a-d008c774ac78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean values are: [0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mv = np.mean(X_train,axis=0)\n",
    "print(f\"Mean values are: {mv}\")\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(X_train[:,0])\n",
    "plt.grid(True)\n",
    "plt.title(\"Age\");\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(X_train[:,1])\n",
    "plt.grid(True)\n",
    "plt.title(\"Salary\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Logistic regression is used as a classifier\n",
    "\n",
    "$$\n",
    "\\ln \\frac {p}{1-p} = b_0 + b_1 x_1 \\\\\n",
    "\\hat p \\equiv \\text {probability prediction} \\to \\hat y\n",
    "$$\n",
    "\n",
    "- predicts a class: 0 or 1\n",
    "- feature scaleing is **not requried**, but will improve performance\n",
    "- since y will be categorical (0 or 1), you shouldn't need to scale it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[65  3]\n",
      " [ 8 24]]\n",
      "-------------------\n",
      "\u001b[32mTrue Positives (TP): 65\n",
      "True Negatives (TN): 24\n",
      "\u001b[31mFalse Positives (FP): 3\n",
      "False Negatives (FN): 8\u001b[39m\n",
      "-------------------\n",
      "Accuracy: 89.0%\n",
      "Prediction: [0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state = 0)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bb6jCOCQiAmP"
   },
   "source": [
    "## K-Nearest Neighbor\n",
    "\n",
    "The K-nearest neighbors (KNN) algorithm is a simple, easy-to-implement supervised machine learning algorithm that can be used to solve both classification and regression problems. The algorithm assumes that similar things exist in close proximity to each other as shown below. This method is a **nonlinear** classifier.\n",
    "\n",
    "![](knn-pics/knn-plot.png)\n",
    "\n",
    "KNN works by finding the distances between a query and all the examples in the data, selecting the specified number examples (K) closest to the query, then votes for the most frequent label (in the case of classification) or averages the labels (in the case of regression).\n",
    "\n",
    "Distance functions:\n",
    "\n",
    "$$\n",
    "L1 = \\sum_P \\lvert X_1^P - X_2^p \\rvert \\\\\n",
    "L2 = \\sqrt {\\sum_P (X_1^P - X_2^p)^2}\n",
    "$$\n",
    "\n",
    "For the L2, you don't really need to do the square root, because it is monotonic and won't change the ordering of the nearest neigherbors.\n",
    "\n",
    "1. Pick K neighbors, common is 5\n",
    "1. Use the Euclidean distance to calculate K nearest neighbors\n",
    "1. Count the number of data points in each neighbor\n",
    "1. Assign points in NN\n",
    "\n",
    "If K = 1, then it becomes the nearest neighbor, which is generally not used.\n",
    "\n",
    "**Note:** it is easy to train, but expensive to use at execution because it must remember all training data. \n",
    "\n",
    "### References\n",
    "\n",
    "- wikipedia: [k-nearest neighbors algorithm](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)\n",
    "- [Machine Learning Basics with the K-Nearest Neighbors Algorithm](https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3505,
     "status": "ok",
     "timestamp": 1588492963427,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "D6bpZwUiiXic",
    "outputId": "ec9468d5-c478-4ffa-ba1c-535eb56d7304"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[64  4]\n",
      " [ 3 29]]\n",
      "-------------------\n",
      "\u001b[32mTrue Positives (TP): 64\n",
      "True Negatives (TN): 29\n",
      "\u001b[31mFalse Positives (FP): 4\n",
      "False Negatives (FN): 3\u001b[39m\n",
      "-------------------\n",
      "Accuracy: 93.0%\n",
      "Prediction: [0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)\n",
    "\n",
    "SVM are th eriskiest/extreme types of classifyers because of the support vector and often perform the best.\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/SVM_margin.png/300px-SVM_margin.png)\n",
    "\n",
    "SVM tries to draw a linear line through the dataset with a boundry (dotted line in image above). The vectors which lie on this boundry (margin) are the supporting vectors and give this method its name. The margin are the extremes of the classes you are trying to classify\n",
    "\n",
    "$$\n",
    "f(x_i, w)_j \\to s_j \\\\\n",
    "Loss(L_i) = \\sum_{j \\ne y_i} \\max { O_j s_j - s_{y_i} + b }\n",
    "$$\n",
    "\n",
    "- L2 penalty perfers smaller and more diffuse weight vectors\n",
    "\n",
    "### References\n",
    "\n",
    "- wikipedia: [Support vector machine](https://en.wikipedia.org/wiki/Support_vector_machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[66  2]\n",
      " [ 8 24]]\n",
      "-------------------\n",
      "\u001b[32mTrue Positives (TP): 66\n",
      "True Negatives (TN): 24\n",
      "\u001b[31mFalse Positives (FP): 2\n",
      "False Negatives (FN): 8\u001b[39m\n",
      "-------------------\n",
      "Accuracy: 90.0%\n",
      "Prediction: [0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel = 'linear', random_state = 0)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel SVM\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/512px-Kernel_Machine.svg.png)\n",
    "\n",
    "Kernel SVM does a similar thing to the standard SVM, except, it uses a nonlinear kernel to map the dataset into a new space where the SVM method can be applied. In the picture above, the original nonlinear divide between black/white dots is transformed into a linear one via the kernel.\n",
    "\n",
    "### References\n",
    "\n",
    "- wikipedia: [Support vector machine](https://en.wikipedia.org/wiki/Support_vector_machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[64  4]\n",
      " [ 3 29]]\n",
      "-------------------\n",
      "\u001b[32mTrue Positives (TP): 64\n",
      "True Negatives (TN): 29\n",
      "\u001b[31mFalse Positives (FP): 4\n",
      "False Negatives (FN): 3\u001b[39m\n",
      "-------------------\n",
      "Accuracy: 93.0%\n",
      "Prediction: [0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "ksvm = SVC(kernel = 'rbf', random_state = 0)\n",
    "ksvm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ksvm.predict(X_test)\n",
    "\n",
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "Decision tree learning is one of the predictive modelling approaches used in statistics, data mining and machine learning. It uses a decision tree (as a predictive model) to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). \n",
    "\n",
    "![](https://miro.medium.com/max/360/1*XMId5sJqPtm8-RIwVVz2tg.png)\n",
    "\n",
    "### References\n",
    "\n",
    "- [Decision Trees in Machine Learning](https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052)\n",
    "- wikipedia: [Decision tree learning](https://en.wikipedia.org/wiki/Decision_tree_learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[62  6]\n",
      " [ 3 29]]\n",
      "-------------------\n",
      "\u001b[32mTrue Positives (TP): 62\n",
      "True Negatives (TN): 29\n",
      "\u001b[31mFalse Positives (FP): 6\n",
      "False Negatives (FN): 3\u001b[39m\n",
      "-------------------\n",
      "Accuracy: 91.0%\n",
      "Prediction: [0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest (Ensemble Learning)\n",
    "\n",
    "Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean/average prediction (regression) of the individual trees. Random decision forests correct for decision trees' habit of overfitting to their training set. Random forests generally outperform decision trees, but their accuracy is lower than gradient boosted trees. However, data characteristics can affect their performance.\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/7/76/Random_forest_diagram_complete.png)\n",
    "\n",
    "### References\n",
    "\n",
    "- wikipedia: [Random forest](https://en.wikipedia.org/wiki/Random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[63  5]\n",
      " [ 4 28]]\n",
      "-------------------\n",
      "\u001b[32mTrue Positives (TP): 63\n",
      "True Negatives (TN): 28\n",
      "\u001b[31mFalse Positives (FP): 5\n",
      "False Negatives (FN): 4\u001b[39m\n",
      "-------------------\n",
      "Accuracy: 91.0%\n",
      "Prediction: [0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO/71HmJztjHpR9Q3DXpRZQ",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "k_nearest_neighbors.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
